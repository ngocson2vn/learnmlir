//
// Generated by LLVM NVPTX Back-End
//

.version 8.6
.target sm_86
.address_size 64

	// .globl	add_kernel              // -- Begin function add_kernel
                                        // @add_kernel
.visible .entry add_kernel(
	.param .u64 .ptr .global .align 1 add_kernel_param_0,
	.param .u64 .ptr .global .align 1 add_kernel_param_1,
	.param .u64 .ptr .global .align 1 add_kernel_param_2,
	.param .u32 add_kernel_param_3,
	.param .u64 .ptr .global .align 1 add_kernel_param_4
)
.reqntid 128
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<8>;

// %bb.0:
	ld.param.b64 	%rd4, [add_kernel_param_0];
	ld.param.b64 	%rd5, [add_kernel_param_1];
	mov.u32 	%r4, %ctaid.x;
	shl.b32 	%r5, %r4, 6;
	ld.param.b64 	%rd6, [add_kernel_param_2];
	ld.param.b32 	%r6, [add_kernel_param_3];
	mov.u32 	%r7, %tid.x;
	and.b32 	%r8, %r7, 63;
	or.b32 	%r9, %r5, %r8;
	setp.lt.s32 	%p1, %r9, %r6;
	mul.wide.s32 	%rd7, %r9, 4;
	add.s64 	%rd1, %rd4, %rd7;
	// begin inline asm
	mov.u32 %r1, 0x0;
	@%p1 ld.global.b32 { %r1 }, [ %rd1 + 0 ];
	// end inline asm
	add.s64 	%rd2, %rd5, %rd7;
	// begin inline asm
	mov.u32 %r2, 0x0;
	@%p1 ld.global.b32 { %r2 }, [ %rd2 + 0 ];
	// end inline asm
	add.rn.f32 	%r3, %r1, %r2;
	add.s64 	%rd3, %rd6, %rd7;
	and.b32 	%r10, %r7, 64;
	setp.eq.s32 	%p4, %r10, 0;
	and.pred 	%p3, %p4, %p1;
	// begin inline asm
	@%p3 st.global.b32 [ %rd3 + 0 ], { %r3 };
	// end inline asm
	ret;
                                        // -- End function
}
